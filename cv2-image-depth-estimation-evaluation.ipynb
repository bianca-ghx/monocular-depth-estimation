{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:24:57.953426Z",
     "iopub.status.busy": "2023-05-17T17:24:57.952968Z",
     "iopub.status.idle": "2023-05-17T17:24:57.963695Z",
     "shell.execute_reply": "2023-05-17T17:24:57.961511Z",
     "shell.execute_reply.started": "2023-05-17T17:24:57.953389Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, LeakyReLU, Concatenate, Layer, InputSpec\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import DenseNet169, DenseNet121\n",
    "from keras.models import load_model\n",
    "import keras.utils.conv_utils as conv_utils\n",
    "import keras.backend as K\n",
    "from skimage.transform import resize\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:24:57.966555Z",
     "iopub.status.busy": "2023-05-17T17:24:57.966173Z",
     "iopub.status.idle": "2023-05-17T17:25:03.160890Z",
     "shell.execute_reply": "2023-05-17T17:25:03.159832Z",
     "shell.execute_reply.started": "2023-05-17T17:24:57.966523Z"
    }
   },
   "outputs": [],
   "source": [
    "# choose whether to use our model or pretrained model\n",
    "method = input(\"Choose which model to use - checkpoints | pretrained:\")\n",
    "print(f\"Using {method} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:25:03.163307Z",
     "iopub.status.busy": "2023-05-17T17:25:03.162412Z",
     "iopub.status.idle": "2023-05-17T17:25:08.214549Z",
     "shell.execute_reply": "2023-05-17T17:25:08.213604Z",
     "shell.execute_reply.started": "2023-05-17T17:25:03.163270Z"
    }
   },
   "outputs": [],
   "source": [
    "# choose pretrained model for the encoder\n",
    "pretrained_enc_model = input(\"Choose model used for encoder - DenseNet121 | DenseNet169:\")\n",
    "print(f\"Using {pretrained_enc_model} for the encoder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model from Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:25:08.219277Z",
     "iopub.status.busy": "2023-05-17T17:25:08.218983Z",
     "iopub.status.idle": "2023-05-17T17:25:08.227735Z",
     "shell.execute_reply": "2023-05-17T17:25:08.226716Z",
     "shell.execute_reply.started": "2023-05-17T17:25:08.219252Z"
    }
   },
   "outputs": [],
   "source": [
    "class UpscaleBlock(Model):\n",
    "    # Define an upscaling block with skip connections\n",
    "    def __init__(self, filters, name):\n",
    "        super(UpscaleBlock, self).__init__()\n",
    "        self.up = UpSampling2D(size=(2, 2), interpolation='bilinear', name=name + '_upsampling2d')\n",
    "        self.concat = Concatenate(name=name + '_concat')\n",
    "        self.convA = Conv2D(filters, 3, 1, 'same', name=name + '_convA')\n",
    "        self.reluA = LeakyReLU(alpha=0.2)\n",
    "        self.convB = Conv2D(filters, 3, 1, 'same', name=name + '_convB')\n",
    "        self.reluB = LeakyReLU(alpha=0.2)\n",
    "\n",
    "    # Define the forward pass through the block\n",
    "   \n",
    "    def call(self, x):\n",
    "        upsampled = self.up(x[0]) # Upsample the input tensor\n",
    "        concatenated = self.concat([upsampled, x[1]]) # Concatenate the upsampled tensor with the skip connection\n",
    "        convA_output = self.reluA(self.convA(concatenated)) # Perform the convolution and apply the LeakyReLU activation function\n",
    "        convB_output = self.reluB(self.convB(convA_output)) # Perform another convolution and apply the LeakyReLU activation function\n",
    "        return convB_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:25:08.230402Z",
     "iopub.status.busy": "2023-05-17T17:25:08.229725Z",
     "iopub.status.idle": "2023-05-17T17:25:08.249831Z",
     "shell.execute_reply": "2023-05-17T17:25:08.248707Z",
     "shell.execute_reply.started": "2023-05-17T17:25:08.230346Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(Model):\n",
    "    # Define an encoder based on the DenseNet-169 architecture\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        if pretrained_enc_model == 'DenseNet121':\n",
    "            self.base_model = DenseNet121(input_shape=(None, None, 3), include_top=False, weights='imagenet')   \n",
    "            print('Base model loaded {}'.format(DenseNet121.__name__))\n",
    "        elif pretrained_enc_model == 'DenseNet169':\n",
    "            self.base_model = DenseNet169(input_shape=(None, None, 3), include_top=False, weights='imagenet')   \n",
    "            print('Base model loaded {}'.format(DenseNet169.__name__))\n",
    "        \n",
    "        layer_names = ['pool1', 'pool2_pool', 'pool3_pool', 'conv1/relu']\n",
    "        outputs = [self.base_model.get_layer(name).output for name in layer_names]\n",
    "        outputs.insert(0, self.base_model.outputs[-1])\n",
    "        self.encoder = Model(inputs=self.base_model.inputs, outputs=outputs)\n",
    "\n",
    "    # Define the forward pass through the encoder\n",
    "    def call(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:25:08.251914Z",
     "iopub.status.busy": "2023-05-17T17:25:08.251285Z",
     "iopub.status.idle": "2023-05-17T17:25:08.265805Z",
     "shell.execute_reply": "2023-05-17T17:25:08.264933Z",
     "shell.execute_reply.started": "2023-05-17T17:25:08.251882Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(Model):\n",
    "    # Define a decoder with skip connections and upscaling blocks\n",
    "    def __init__(self, decode_filters):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.conv2 = Conv2D(decode_filters, 1, padding='same', name='conv2')\n",
    "        self.up1 = UpscaleBlock(decode_filters // 2, name='up1')\n",
    "        self.up2 = UpscaleBlock(decode_filters // 4, name='up2')\n",
    "        self.up3 = UpscaleBlock(decode_filters // 8, name='up3')\n",
    "        self.up4 = UpscaleBlock(decode_filters // 16, name='up4')\n",
    "        self.conv3 = Conv2D(1, 3, 1, padding='same', name='conv3')\n",
    "\n",
    "    # Define the forward pass through the decoder\n",
    "    def call(self, features):\n",
    "        x, pool1, pool2, pool3, conv1 = features\n",
    "        up0 = self.conv2(x) # Perform a convolution on the input tensor\n",
    "        up1 = self.up1([up0, pool3]) # Apply an upscaling block with skip connections\n",
    "        up2 = self.up2([up1, pool2]) # Apply another upscaling block with skip connections\n",
    "        up3 = self.up3([up2, pool1]) # Apply another upscaling block with skip connections\n",
    "        up4 = self.up4([up3, conv1]) # Apply another upscaling block with skip connections\n",
    "        return self.conv3(up4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:25:08.267893Z",
     "iopub.status.busy": "2023-05-17T17:25:08.267215Z",
     "iopub.status.idle": "2023-05-17T17:25:08.280105Z",
     "shell.execute_reply": "2023-05-17T17:25:08.279048Z",
     "shell.execute_reply.started": "2023-05-17T17:25:08.267861Z"
    }
   },
   "outputs": [],
   "source": [
    "class DepthEstimate(Model):\n",
    "    # Define the full depth estimation model\n",
    "    def __init__(self):\n",
    "        super(DepthEstimate, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder(decode_filters=int(self.encoder.layers[-1].output[0].shape[-1] // 2))\n",
    "        print('\\nModel created.')\n",
    "\n",
    "    # Define the forward pass through the depth estimation model\n",
    "    def call(self, x):\n",
    "        return self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-17T17:25:08.282214Z",
     "iopub.status.busy": "2023-05-17T17:25:08.281614Z",
     "iopub.status.idle": "2023-05-17T17:25:08.291914Z",
     "shell.execute_reply": "2023-05-17T17:25:08.290885Z",
     "shell.execute_reply.started": "2023-05-17T17:25:08.282139Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if the method is set to \"checkpoints\"\n",
    "if method == \"checkpoints\":\n",
    "    # Create an instance of the DepthEstimate model\n",
    "    model = DepthEstimate()\n",
    "    \n",
    "    # Define the path to the checkpoint file based on the pretrained_enc_model variable\n",
    "    checkpoint_path = f\"/kaggle/input/{pretrained_enc_model.lower()}-checkpoints/training_1/cp.ckpt\"\n",
    "    \n",
    "    # Load the weights of the model from the checkpoint file\n",
    "    model.load_weights(checkpoint_path)\n",
    "    \n",
    "    # Print a message to indicate that the model weights have been successfully loaded\n",
    "    print('Model weights loaded.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:25:08.294138Z",
     "iopub.status.busy": "2023-05-17T17:25:08.293467Z",
     "iopub.status.idle": "2023-05-17T17:25:08.309907Z",
     "shell.execute_reply": "2023-05-17T17:25:08.308741Z",
     "shell.execute_reply.started": "2023-05-17T17:25:08.294105Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_data_format(value):\n",
    "    # Check if the value is None, if so, use the current data format\n",
    "    data_format = K.image_data_format() if value is None else value.lower()\n",
    "    \n",
    "    # Check if the data format is valid, it should be either 'channels_first' or 'channels_last'\n",
    "    if data_format not in {'channels_first', 'channels_last'}:\n",
    "        # Raise a ValueError if the data format is not valid\n",
    "        raise ValueError('The `data_format` argument must be one of '\n",
    "                         '\"channels_first\", \"channels_last\". Received: ' +\n",
    "                         str(value))\n",
    "    \n",
    "    # Return the normalized data format\n",
    "    return data_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:25:08.316750Z",
     "iopub.status.busy": "2023-05-17T17:25:08.315942Z",
     "iopub.status.idle": "2023-05-17T17:25:08.329032Z",
     "shell.execute_reply": "2023-05-17T17:25:08.328097Z",
     "shell.execute_reply.started": "2023-05-17T17:25:08.316717Z"
    }
   },
   "outputs": [],
   "source": [
    "class BilinearUpSampling2D(Layer):\n",
    "    def __init__(self, size=(2, 2), data_format=None, **kwargs):\n",
    "        # Initialize the BilinearUpSampling2D layer\n",
    "        super(BilinearUpSampling2D, self).__init__(**kwargs)\n",
    "        \n",
    "        # Normalize the data format and assign it to the layer\n",
    "        self.data_format = normalize_data_format(data_format)\n",
    "        \n",
    "        # Normalize the size tuple and assign it to the layer\n",
    "        self.size = conv_utils.normalize_tuple(size, 2, 'size')\n",
    "        \n",
    "        # Specify the input shape of the layer\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # Compute the output shape of the layer based on the input shape and the size\n",
    "        height = self.size[0] * input_shape[2] if self.data_format == 'channels_first' else self.size[0] * input_shape[1]\n",
    "        width = self.size[1] * input_shape[3] if self.data_format == 'channels_first' else self.size[1] * input_shape[2]\n",
    "        \n",
    "        # Return the computed output shape as a tuple\n",
    "        return tuple(input_shape[:2]) + (height, width)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Get the shape of the input tensor\n",
    "        input_shape = K.shape(inputs)\n",
    "        \n",
    "        # Compute the height and width of the output tensor based on the size and data format\n",
    "        height = self.size[0] * input_shape[2] if self.data_format == 'channels_first' else self.size[0] * input_shape[1]\n",
    "        width = self.size[1] * input_shape[3] if self.data_format == 'channels_first' else self.size[1] * input_shape[2]\n",
    "        \n",
    "        # Resize the input tensor using bilinear interpolation\n",
    "        return tf.image.resize(inputs, [height, width], method=tf.image.ResizeMethod.BILINEAR)\n",
    "\n",
    "    def get_config(self):\n",
    "        # Get the configuration of the layer, including the size and data format\n",
    "        config = {'size': self.size, 'data_format': self.data_format}\n",
    "        \n",
    "        # Get the base configuration from the superclass\n",
    "        base_config = super(BilinearUpSampling2D, self).get_config()\n",
    "        \n",
    "        # Merge the base configuration and the layer-specific configuration\n",
    "        return {**base_config, **config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:25:08.331813Z",
     "iopub.status.busy": "2023-05-17T17:25:08.330952Z",
     "iopub.status.idle": "2023-05-17T17:25:08.344521Z",
     "shell.execute_reply": "2023-05-17T17:25:08.343417Z",
     "shell.execute_reply.started": "2023-05-17T17:25:08.331751Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom object needed for inference and training\n",
    "custom_objects = {'BilinearUpSampling2D': BilinearUpSampling2D, 'depth_loss_function': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:25:08.346520Z",
     "iopub.status.busy": "2023-05-17T17:25:08.346022Z",
     "iopub.status.idle": "2023-05-17T17:25:14.079617Z",
     "shell.execute_reply": "2023-05-17T17:25:14.078563Z",
     "shell.execute_reply.started": "2023-05-17T17:25:08.346485Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if the method is set to \"pretrained\"\n",
    "if method == \"pretrained\":\n",
    "    # Load the pretrained model from the specified path\n",
    "    model = load_model('/kaggle/input/depth-pretrained-models/nyu.h5', custom_objects=custom_objects, compile=False)\n",
    "    \n",
    "    # Print a message to indicate that the pretrained model has been loaded\n",
    "    print(\"Loaded pretrained model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:25:14.082706Z",
     "iopub.status.busy": "2023-05-17T17:25:14.081890Z",
     "iopub.status.idle": "2023-05-17T17:25:14.089875Z",
     "shell.execute_reply": "2023-05-17T17:25:14.088776Z",
     "shell.execute_reply.started": "2023-05-17T17:25:14.082666Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    # Print a message to indicate that the test data loading has started\n",
    "    print('Loading test data...', end='')\n",
    "    \n",
    "    # Load the RGB, depth, and crop data from the specified files\n",
    "    rgb = np.load('/kaggle/input/nyu-test-data/eigen_test_rgb.npy')\n",
    "    depth = np.load('/kaggle/input/nyu-test-data/eigen_test_depth.npy')\n",
    "    crop = np.load('/kaggle/input/nyu-test-data/eigen_test_crop.npy')\n",
    "    \n",
    "    # Print a message to indicate that the test data has been successfully loaded\n",
    "    print('Test data loaded.\\n')\n",
    "    \n",
    "    # Return the loaded RGB, depth, and crop data\n",
    "    return rgb, depth, crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:25:14.091875Z",
     "iopub.status.busy": "2023-05-17T17:25:14.091275Z",
     "iopub.status.idle": "2023-05-17T17:25:14.110581Z",
     "shell.execute_reply": "2023-05-17T17:25:14.109693Z",
     "shell.execute_reply.started": "2023-05-17T17:25:14.091838Z"
    }
   },
   "outputs": [],
   "source": [
    "def DepthNorm(x, maxDepth):\n",
    "    return maxDepth / x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:25:14.112797Z",
     "iopub.status.busy": "2023-05-17T17:25:14.112016Z",
     "iopub.status.idle": "2023-05-17T17:25:14.123089Z",
     "shell.execute_reply": "2023-05-17T17:25:14.122156Z",
     "shell.execute_reply.started": "2023-05-17T17:25:14.112764Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, images, minDepth=10, maxDepth=1000, batch_size=2):\n",
    "    # Ensure the images have the correct dimensions\n",
    "    images = np.atleast_3d(images)\n",
    "    if images.shape[-1] != 3: \n",
    "        images = np.repeat(images[..., np.newaxis], 3, axis=-1)\n",
    "    images = images[np.newaxis, ...] if images.ndim == 3 else images\n",
    "\n",
    "    # Compute and normalize predictions\n",
    "    predictions = model.predict(images, batch_size=batch_size)\n",
    "    normalized_predictions = DepthNorm(predictions, maxDepth=1000)\n",
    "\n",
    "    return np.clip(normalized_predictions, minDepth, maxDepth) / maxDepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:25:14.124899Z",
     "iopub.status.busy": "2023-05-17T17:25:14.124561Z",
     "iopub.status.idle": "2023-05-17T17:25:14.135286Z",
     "shell.execute_reply": "2023-05-17T17:25:14.134417Z",
     "shell.execute_reply.started": "2023-05-17T17:25:14.124866Z"
    }
   },
   "outputs": [],
   "source": [
    "def scale_up(scale, images):\n",
    "    # Create an empty list to store the scaled images\n",
    "    scaled = []\n",
    "\n",
    "    # Iterate over each image in the input list\n",
    "    for img in images:\n",
    "        # Compute the output shape of the scaled image based on the specified scale\n",
    "        output_shape = (scale * img.shape[0], scale * img.shape[1])\n",
    "        \n",
    "        # Resize the image using the specified output shape and other parameters\n",
    "        # Preserve the range of pixel values and apply reflection padding and anti-aliasing\n",
    "        scaled.append(resize(img, output_shape, order=1, preserve_range=True, mode='reflect', anti_aliasing=True))\n",
    "\n",
    "    # Stack the scaled images along a new axis to create a single array\n",
    "    return np.stack(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:25:14.139050Z",
     "iopub.status.busy": "2023-05-17T17:25:14.138323Z",
     "iopub.status.idle": "2023-05-17T17:25:14.154316Z",
     "shell.execute_reply": "2023-05-17T17:25:14.153301Z",
     "shell.execute_reply.started": "2023-05-17T17:25:14.139005Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, rgb, depth, crop, batch_size=6):\n",
    "    def compute_errors(gt, pred):\n",
    "        # Compute the error metrics between the ground truth and predicted depth maps\n",
    "        ratio = np.maximum(gt / pred, pred / gt)\n",
    "        a1 = (ratio < 1.25).mean()\n",
    "        a2 = (ratio < 1.25 ** 2).mean()\n",
    "        a3 = (ratio < 1.25 ** 3).mean()\n",
    "        abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "        rmse = np.sqrt(((gt - pred) ** 2).mean())\n",
    "        log_10 = np.abs(np.log10(gt) - np.log10(pred)).mean()\n",
    "\n",
    "        return a1, a2, a3, abs_rel, rmse, log_10\n",
    "\n",
    "    # Initialize an array to store the depth scores for each evaluation sample\n",
    "    depth_scores = np.zeros((6, len(rgb)))\n",
    "\n",
    "    # Iterate over the evaluation samples in batches\n",
    "    for i in range(len(rgb)//batch_size):    \n",
    "        start, end = i*batch_size, (i+1)*batch_size\n",
    "\n",
    "        # Get the RGB images and ground truth depth maps for the current batch\n",
    "        x = rgb[start:end]\n",
    "        true_y = depth[start:end]\n",
    "        \n",
    "        # Predict depth maps for the current batch using the model\n",
    "        pred_y = scale_up(2, predict(model, x / 255, minDepth=10, maxDepth=1000, batch_size=batch_size)[:, :, :, 0]) * 10.0\n",
    "        pred_y_flip = scale_up(2, predict(model, x[..., ::-1, :] / 255, minDepth=10, maxDepth=1000, batch_size=batch_size)[:, :, :, 0]) * 10.0\n",
    "\n",
    "        # Crop the ground truth and predicted depth maps based on the specified crop region\n",
    "        true_y = true_y[:, crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
    "        pred_y = pred_y[:, crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
    "        pred_y_flip = pred_y_flip[:, crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
    "        \n",
    "        # Compute the error metrics for each evaluation sample in the batch\n",
    "        for j, y in enumerate(true_y):\n",
    "            errors = compute_errors(y, 0.5 * (pred_y[j] + np.fliplr(pred_y_flip[j])))\n",
    "            depth_scores[:, start + j] = errors\n",
    "\n",
    "    # Compute the mean error metrics over all evaluation samples\n",
    "    e = depth_scores.mean(axis=1)\n",
    "\n",
    "    # Print the error metrics\n",
    "    print(f\"{'a1':>10}, {'a2':>10}, {'a3':>10}, {'rel':>10}, {'rms':>10}, {'log_10':>10}\")\n",
    "    print(f\"{e[0]:10.4f}, {e[1]:10.4f}, {e[2]:10.4f}, {e[3]:10.4f}, {e[4]:10.4f}, {e[5]:10.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:25:14.157668Z",
     "iopub.status.busy": "2023-05-17T17:25:14.156828Z",
     "iopub.status.idle": "2023-05-17T17:28:29.911225Z",
     "shell.execute_reply": "2023-05-17T17:28:29.910080Z",
     "shell.execute_reply.started": "2023-05-17T17:25:14.157634Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rgb, depth, crop = load_test_data()\n",
    "evaluate(model, rgb, depth, crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:28:29.914024Z",
     "iopub.status.busy": "2023-05-17T17:28:29.913256Z",
     "iopub.status.idle": "2023-05-17T17:28:29.920751Z",
     "shell.execute_reply": "2023-05-17T17:28:29.919614Z",
     "shell.execute_reply.started": "2023-05-17T17:28:29.913957Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_images(image_files):\n",
    "    # Load and preprocess the images from the specified list of image files\n",
    "    loaded_images = [np.clip(np.asarray(Image.open(file), dtype=float) / 255, 0, 1) for file in image_files]\n",
    "    \n",
    "    # Stack the loaded images along a new axis to create a single array\n",
    "    return np.stack(loaded_images, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:28:29.922698Z",
     "iopub.status.busy": "2023-05-17T17:28:29.922309Z",
     "iopub.status.idle": "2023-05-17T17:28:29.935012Z",
     "shell.execute_reply": "2023-05-17T17:28:29.934074Z",
     "shell.execute_reply.started": "2023-05-17T17:28:29.922665Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_multichannel(i):\n",
    "    # Check if the input image is already in the multichannel format\n",
    "    if i.shape[2] == 3:\n",
    "        # If it is, return the input image as it is\n",
    "        return i\n",
    "    \n",
    "    # If the input image has a single channel, repeat the channel values to create a multichannel image\n",
    "    return np.repeat(i[:, :, 0][:, :, np.newaxis], 3, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:28:29.936785Z",
     "iopub.status.busy": "2023-05-17T17:28:29.936446Z",
     "iopub.status.idle": "2023-05-17T17:28:29.951586Z",
     "shell.execute_reply": "2023-05-17T17:28:29.950572Z",
     "shell.execute_reply.started": "2023-05-17T17:28:29.936754Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_images(outputs, inputs=None, gt=None, is_colormap=True, is_rescale=True):\n",
    "    # Helper function to process an image by converting it to multichannel and resizing it\n",
    "    def process_img(img, shape):\n",
    "        img = to_multichannel(img)\n",
    "        return resize(img, shape, preserve_range=True, mode='reflect', anti_aliasing=True)\n",
    "\n",
    "    # Get the 'plasma' colormap from matplotlib\n",
    "    plasma = plt.get_cmap('plasma')\n",
    "    \n",
    "    # Define the shape of the output images\n",
    "    shape = (outputs[0].shape[0], outputs[0].shape[1], 3)\n",
    "\n",
    "    # Initialize a list to store all the images\n",
    "    all_images = []\n",
    "    \n",
    "    # Iterate over the outputs\n",
    "    for i in range(outputs.shape[0]):\n",
    "        # Initialize a list to store the images for the current output\n",
    "        imgs = []\n",
    "        \n",
    "        # Add the input image to the list of images if available\n",
    "        if isinstance(inputs, (list, tuple, np.ndarray)):\n",
    "            imgs.append(process_img(inputs[i], shape))\n",
    "\n",
    "        # Add the ground truth image to the list of images if available\n",
    "        if isinstance(gt, (list, tuple, np.ndarray)):\n",
    "            imgs.append(process_img(gt[i], shape))\n",
    "\n",
    "        # Add the output image to the list of images\n",
    "        if is_colormap:\n",
    "            # If using a colormap, extract the output depth map and apply colormap\n",
    "            rescaled = outputs[i][:,:,0]\n",
    "            if is_rescale:\n",
    "                rescaled = (rescaled - np.min(rescaled)) / np.max(rescaled)\n",
    "            imgs.append(plasma(rescaled)[:,:,:3])\n",
    "        else:\n",
    "            # If not using a colormap, convert the output to multichannel\n",
    "            imgs.append(to_multichannel(outputs[i]))\n",
    "\n",
    "        # Concatenate the images horizontally and add them to the list of all images\n",
    "        all_images.append(np.hstack(imgs))\n",
    "\n",
    "    # Create a montage of all the images and return it\n",
    "    return skimage.util.montage(np.stack(all_images), channel_axis=-1, fill=(0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:28:29.953392Z",
     "iopub.status.busy": "2023-05-17T17:28:29.952955Z",
     "iopub.status.idle": "2023-05-17T17:28:30.079499Z",
     "shell.execute_reply": "2023-05-17T17:28:30.078431Z",
     "shell.execute_reply.started": "2023-05-17T17:28:29.953287Z"
    }
   },
   "outputs": [],
   "source": [
    "directory = '/kaggle/input/nyu-depth-v2/nyu_data/data/nyu2_test'\n",
    "\n",
    "# Get the paths of files ending with \"_colors.png\" in the specified directory\n",
    "color_file_paths = [\n",
    "    os.path.join(directory, filename)\n",
    "    for filename in os.listdir(directory)\n",
    "    if filename.endswith('_colors.png')\n",
    "]\n",
    "\n",
    "# Get the total number of color file paths\n",
    "total_size = len(color_file_paths)\n",
    "\n",
    "# Select a specified number of color file paths randomly\n",
    "select_size = 9\n",
    "color_file_paths = random.choices(color_file_paths, k=select_size)\n",
    "\n",
    "# Print the information about the selected random images\n",
    "print(\"Selected \", select_size, \" random images from a total of \", total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:28:30.081867Z",
     "iopub.status.busy": "2023-05-17T17:28:30.081170Z",
     "iopub.status.idle": "2023-05-17T17:28:51.994898Z",
     "shell.execute_reply": "2023-05-17T17:28:51.993979Z",
     "shell.execute_reply.started": "2023-05-17T17:28:30.081830Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input images\n",
    "inputs = load_images(color_file_paths)\n",
    "print('\\nLoaded ({0}) images of size {1}.'.format(inputs.shape[0], inputs.shape[1:]))\n",
    "\n",
    "# Compute results\n",
    "outputs = predict(model, inputs)\n",
    "\n",
    "# Display results\n",
    "viz = display_images(outputs.copy(), inputs.copy())\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(viz)\n",
    "plt.axis('off')\n",
    "plt.title('Random Test Images and Predicted Depth Maps')\n",
    "# plt.savefig('test.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
